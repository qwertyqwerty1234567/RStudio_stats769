---
title: "Lab8"
author: "jche827"
date: "3/10/2021"
output: html_document
---

# The Data Set

The data source for this lab is from UCI Machine Learning Repository. The data is a biomedical data set built by Dr. Henrique da Mota. The data have been organized in two different but related classification tasks. The first task consists in classifying patients as belonging to one out of three categories: Normal (100 patients), Disk Hernia (60 patients) or Spondylolisthesis (150 patients). For the second task, the categories Disk Hernia and Spondylolisthesis were merged into a single category labelled as 'abnormal'. Thus, the second task consists in classifying patients as belonging to one out of two categories: Normal (100 patients) or Abnormal (210 patients). We are using the Vertebral Column data set. 

# Import
```{r}
vc = read.csv("vertebral-column.csv", stringsAsFactors=TRUE)
head(vc)

# load libraries
library(MASS)
library(class)
library(gam)
library(nnet)
library(e1071)
library(parallel)
```

# Exploration

## 1. Create a pairwise scatterplot, with observations of different classes shown in different colors.
```{r}
plot(vc[,-7], col=as.numeric(vc[,7])+1)
```

# Classification

## 2. Linear discriminant analysis
```{r, results = FALSE}
(r = lda(class ~ pi + pt + lla + ss + pr + gos, data=vc))
(p1 = predict(r, newdata=vc))
```
```{r}
yhat1 = p1$class
table(vc$class, yhat1)     # confusion table
(A = mean(vc$class == yhat1))    # Classfication accuracy (training/resubstituion)
```
Classification accuracy of Linear discriminant analysis: 81.6129%

## 3. Quadratic discriminant analysis
```{r, results = FALSE}
(r2 = qda(class ~ ., data=vc))
(yhat2 = predict(r2, newdata=vc)$class)
```
```{r}
table(vc$class, yhat2)     # confusion table
(A = mean(vc$class == yhat2))    # Classfication accuracy
```
Classification accuracy of Quadratic discriminant analysis:  87.41935%

## 4. Naive Bayes
```{r, results = FALSE}
(r3 = naiveBayes(class ~ ., data=vc))
(yhat3 = predict(r3, newdata=vc))
```
```{r}
table(vc$class, yhat3)     # confusion table
(A = mean(vc$class == yhat3))    # Classfication accuracy
```
Classification accuracy of Naive Bayes: 83.54839%

## 5. Multinomial logistic regression
```{r}
(r4 = multinom(class ~ ., data=vc))
table(vc$class, predict(r4, vc))    # Confusion table
mean(vc$class == predict(r4, vc))   # classification accuracy
```
Classification accuracy of Multinomial logistic regression: 87.41935%

## 6. K -nearest neighbours (with K=10)
```{r}
yhat5 = knn(train=vc[,4:6], test=vc[,4:6], cl=vc[,7], k=10)   # K = 5
table(vc[,7], yhat5)
(A = mean(vc$class == yhat5)) 
```
Classification accuracy of K -nearest neighbours (with K=10): 88.06452%


# Primary Performance Evaluation

## 7. Present your resulting classification accuracy for all five classification methods in a table
```{r}

```

### From this table, what can we say about the relative performance of these methods for the data set?

# Multiple Logistic Regression and Generalised Additive Models

## 8. Create a response variable from variable class so that both classes DH and SL are relabelled as AB (Abnormal).

### Use glm() to build a multiple logistic regression model for this new class variable, and compute the confusion matrix and resubstitution classification accuracy

## 9. Use step() to find the AIC-selected model, with backward selection.

### Which variables are removed by the AIC?

## 10. Extend the AIC-selected model with gam() so that each linear term is replaced with a smoothing spline of 5 degrees of freedom. Take a visual approach to reasonably lower the degrees of freedom in each term.

### For your chosen model, compute the confusion matrix and classification accuracy

# Cross-validation and Parallel Computing

## 11. Reconsider the 3-class problem studied in Questions 2-7. Use 10 repetitions of 10-fold cross-validation to evaluate the performance of the 5 classification methods

### Present your resulting classification accuracy of all five classification methods in a table. Comment on the results.

## 12. Modify your code so that parallel computing can be used, in which each job running in parallel is only for the computation about one fold out of 10 (i.e., one training set and one test set). Make sure that the same subsamples are used by different methods and that the results are reproducible

### Compare timings with 1, 5, 10, 20 cores

# Summary

In this lab, we looked at different classification methods to predict class based off some variables/features. These methods include: Linear discriminant analysis, Quadratic discriminant analysis, Naive Bayes, Multinomial logistic regression and KNN. We compared confusion matrix and accuracies for them. We altered the class column by combining 2 types into one (abnormal class) and compared results with this new data. We did variable selection with AIC. The 5 classification models were then evaluated with 10 fold cross validation, and then we used parallel computing to compare run times with different numbers of cores used. 






